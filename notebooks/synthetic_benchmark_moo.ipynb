{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6567c57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from itertools import cycle\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as fnn\n",
    "from botorch.acquisition.monte_carlo import qNoisyExpectedImprovement\n",
    "from botorch.acquisition.multi_objective.monte_carlo import (\n",
    "    qExpectedHypervolumeImprovement, qNoisyExpectedHypervolumeImprovement)\n",
    "from botorch.acquisition.multi_objective.objective import \\\n",
    "    IdentityMCMultiOutputObjective\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.models.model_list_gp_regression import ModelListGP\n",
    "from botorch.optim import optimize_acqf\n",
    "from botorch.sampling.normal import SobolQMCNormalSampler\n",
    "from botorch.test_functions.multi_objective import (\n",
    "        DTLZ2,\n",
    "        DTLZ7,\n",
    "        ZDT3,\n",
    "        BraninCurrin,\n",
    "        GMM\n",
    ")\n",
    "from botorch.utils.multi_objective.box_decompositions import \\\n",
    "    NondominatedPartitioning\n",
    "from botorch.utils.multi_objective.hypervolume import (\n",
    "    Hypervolume, infer_reference_point\n",
    ")\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from gpytorch.mlls.sum_marginal_log_likelihood import SumMarginalLogLikelihood\n",
    "from scipy.stats.qmc import LatinHypercube\n",
    "from sklearn.decomposition import PCA\n",
    "from torch import Size\n",
    "\n",
    "from vsd.acquisition import VariationalPreferenceAcquisition\n",
    "from vsd.condproposals import (ConditionalGaussianProposal,\n",
    "                               PreferenceSearchDistribution)\n",
    "from vsd.cpe import PreferenceContinuousCPE, fit_cpe_labels, make_constrastive_alignment_data\n",
    "from vsd.generation import generate_candidates_iw\n",
    "from vsd.preferences import EmpiricalPreferences, UnitNormal, MixtureUnitNormal\n",
    "from vsd.proposals import fit_ml\n",
    "from vsd.utils import is_non_dominated_strict\n",
    "from vsd.labellers import ParetoAnnealed\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99153641",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Config\n",
    "N_INIT = 64\n",
    "BATCH_SIZE = 5\n",
    "GP_BOUNDS = 15\n",
    "N_ITER = 10\n",
    "N_REPS = 10\n",
    "USE_EMPIRICAL_PREFERENCES = False\n",
    "SAMPLES = 128\n",
    "# FUNCTION = \"ZDT3\"\n",
    "# FUNCTION = \"BraninCurrin\"\n",
    "# FUNCTION = \"DTLZ2\"\n",
    "FUNCTION = \"DTLZ2-5\"\n",
    "# FUNCTION = \"DTLZ7\"\n",
    "# FUNCTION = \"GMM\"\n",
    "\n",
    "obj_mappings = {\n",
    "    \"DTLZ2\": dict(f=DTLZ2, args=dict(dim=3, num_objectives=2, negate=True), yscale=None, sigmoid=True, start_scale=3),\n",
    "    \"DTLZ2-5\": dict(f=DTLZ2, args=dict(dim=6, num_objectives=5, negate=True), yscale=None, sigmoid=True, start_scale=2),\n",
    "    \"DTLZ7\": dict(f=DTLZ7, args=dict(dim=7, num_objectives=6, negate=True), yscale=None, sigmoid=True, start_scale=2),\n",
    "    \"BraninCurrin\": dict(f=BraninCurrin, args=dict(negate=False), yscale=[200., 4.], sigmoid=False, start_scale=2.5),\n",
    "    \"ZDT3\": dict(f=ZDT3, args=dict(dim=6, num_objectives=2, negate=True), yscale=None, sigmoid=True, start_scale=2.),\n",
    "    \"GMM\": dict(f=GMM, args=dict(num_objectives=2, negate=True), yscale=None, sigmoid=True, start_scale=2)\n",
    "}\n",
    "\n",
    "plt.rcParams.update(\n",
    "    {\n",
    "        \"font.size\": 12,\n",
    "        \"axes.labelsize\": 14,\n",
    "        \"axes.titlesize\": 16,\n",
    "        \"legend.fontsize\": 10,\n",
    "        \"xtick.labelsize\": 10,\n",
    "        \"ytick.labelsize\": 10,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32fc329",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BBWrapper(obj_mappings[FUNCTION][\"f\"]):\n",
    "    def __init__(self):\n",
    "        super().__init__(**obj_mappings[FUNCTION][\"args\"])\n",
    "        self.yscale = obj_mappings[FUNCTION][\"yscale\"]\n",
    "        if self.yscale is not None:\n",
    "            self.yscale = torch.tensor(self.yscale, dtype=torch.float)\n",
    "\n",
    "    def __call__(self, X):\n",
    "        if obj_mappings[FUNCTION][\"sigmoid\"]:\n",
    "            X = torch.sigmoid(X)\n",
    "        y = super().__call__(X).float()\n",
    "        if self.yscale is not None:\n",
    "            return  y / self.yscale\n",
    "        return y\n",
    "\n",
    "bb = BBWrapper()\n",
    "D = bb.dim if hasattr(bb, \"dim\") else 2\n",
    "# ref_point = bb.ref_point.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9d5c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_init = torch.rand(N_INIT, D)\n",
    "s = obj_mappings[FUNCTION][\"start_scale\"] * 2\n",
    "b = obj_mappings[FUNCTION][\"start_scale\"]\n",
    "X_init = torch.tensor(LatinHypercube(d=D).random(n=N_INIT) * s - b).float()\n",
    "y_init = bb(X_init)\n",
    "M = y_init.shape[1]\n",
    "ref_point = infer_reference_point(y_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e4672a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_inputs(X, Y):\n",
    "    mask = ~torch.isnan(Y).any(dim=1)\n",
    "    return X[mask], Y[mask]\n",
    "\n",
    "def fit_gpytorch_model(mll, num_iter=500):\n",
    "    mll.train()\n",
    "    optimizer = torch.optim.Adam(mll.parameters(), lr=1e-3)\n",
    "\n",
    "    for _ in range(num_iter):\n",
    "        optimizer.zero_grad()\n",
    "        output = mll.model(*mll.model.train_inputs)\n",
    "        loss = -mll(output, mll.model.train_targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        for param in mll.model.parameters():\n",
    "            if param.requires_grad:\n",
    "                param.data.clamp_(min=1e-6)\n",
    "\n",
    "    mll.eval()\n",
    "\n",
    "\n",
    "def fit_gp_moo_model(X, Y):\n",
    "    models = [\n",
    "        SingleTaskGP(X, Y[:, i:i+1])\n",
    "        for i in range(Y.shape[-1])\n",
    "    ]\n",
    "    model = ModelListGP(*models)\n",
    "    mll = SumMarginalLogLikelihood(model.likelihood, model)\n",
    "    fit_gpytorch_model(mll)\n",
    "    return model\n",
    "\n",
    "\n",
    "def fit_gp_sca_model(train_X, train_Y):\n",
    "    weights = torch.rand(M); weights /= weights.sum()\n",
    "    scalar_Y = (train_Y * weights).sum(dim=-1, keepdim=True)\n",
    "    scalar_gp = SingleTaskGP(train_X, scalar_Y)\n",
    "    mll = ExactMarginalLogLikelihood(scalar_gp.likelihood, scalar_gp)\n",
    "    fit_gpytorch_model(mll)\n",
    "    return scalar_gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128b9802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidates_qehvi(model, train_X, train_Y):\n",
    "    sampler = SobolQMCNormalSampler(sample_shape=Size([SAMPLES]))\n",
    "    partitioning = NondominatedPartitioning(ref_point=ref_point, Y=train_Y)\n",
    "    acq_func = qExpectedHypervolumeImprovement(\n",
    "        model=model, ref_point=ref_point.tolist(),\n",
    "        partitioning=partitioning, sampler=sampler,\n",
    "        objective=IdentityMCMultiOutputObjective(outcomes=list(range(train_Y.shape[-1])))\n",
    "    )\n",
    "\n",
    "    candidates, _ = optimize_acqf(\n",
    "        acq_function=acq_func,\n",
    "        bounds=torch.stack([-GP_BOUNDS * torch.ones(D), GP_BOUNDS * torch.ones(D)]),\n",
    "        q=BATCH_SIZE,\n",
    "        num_restarts=10,\n",
    "        raw_samples=SAMPLES,\n",
    "    )\n",
    "    return candidates\n",
    "\n",
    "def generate_candidates_qnehvi(model, train_X, train_Y):\n",
    "    sampler = SobolQMCNormalSampler(sample_shape=torch.Size([SAMPLES]))\n",
    "    acq_func = qNoisyExpectedHypervolumeImprovement(\n",
    "        model=model, X_baseline=train_X, ref_point=ref_point.tolist(),\n",
    "        sampler=sampler,\n",
    "        objective=IdentityMCMultiOutputObjective(outcomes=list(range(train_Y.shape[-1])))\n",
    "    )\n",
    "\n",
    "    candidates, _ = optimize_acqf(\n",
    "        acq_function=acq_func,\n",
    "        bounds=torch.stack([-GP_BOUNDS * torch.ones(D), GP_BOUNDS * torch.ones(D)]),\n",
    "        q=BATCH_SIZE,\n",
    "        num_restarts=10,\n",
    "        raw_samples=SAMPLES,\n",
    "    )\n",
    "    return candidates\n",
    "\n",
    "def generate_candidates_nparego(model, train_X, train_Y):\n",
    "    acq_func = qNoisyExpectedImprovement(\n",
    "        model=model,\n",
    "        X_baseline=train_X,\n",
    "        sampler=SobolQMCNormalSampler(sample_shape=torch.Size([SAMPLES]))\n",
    "    )\n",
    "\n",
    "    candidates, _ = optimize_acqf(\n",
    "        acq_function=acq_func,\n",
    "        bounds=torch.stack([-GP_BOUNDS * torch.ones(D), GP_BOUNDS * torch.ones(D)]),\n",
    "        q=BATCH_SIZE,\n",
    "        num_restarts=10,\n",
    "        raw_samples=SAMPLES,\n",
    "    )\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c55cfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vsd_callback(i, loss, grads):\n",
    "    if (i % 100) == 0:\n",
    "        gmean = sum([g.detach().mean() for g in grads if g is not None]) / len(grads)\n",
    "        print(f\"  {i}: loss = {loss:.3f}, mean grad = {gmean:.3f}\")\n",
    "\n",
    "def callback(i, loss, _):\n",
    "    if (i % 100) == 0:\n",
    "        print(f\"  {i}: loss = {loss:.3f}\")\n",
    "\n",
    "class AGPS():\n",
    "\n",
    "    def __init__(self):\n",
    "        if USE_EMPIRICAL_PREFERENCES:\n",
    "            self.preferences = EmpiricalPreferences()\n",
    "        else:\n",
    "            mu = torch.rand((5, M))\n",
    "            self.preferences = MixtureUnitNormal(locs=mu)\n",
    "            # self.preferences = UnitNormal(dim=M)\n",
    "        self.pareto_cpe = PreferenceContinuousCPE(x_dim=D, u_dims=M, latent_dim=32, dropoutp=0.2, hidden_layers=2)\n",
    "        self.preference_cpe = PreferenceContinuousCPE(x_dim=D, u_dims=M, latent_dim=32, dropoutp=0.2, hidden_layers=2)\n",
    "        prior = torch.distributions.MultivariateNormal(loc=torch.zeros((1, D)), precision_matrix=torch.eye(D) * 0.01)\n",
    "        cproposal = ConditionalGaussianProposal(x_dims=D, u_dims=M, latent_dim=64, hidden_layers=4, bias=True)\n",
    "        self.proposal = PreferenceSearchDistribution(cproposal=cproposal, preference=self.preferences)\n",
    "        self.acq = VariationalPreferenceAcquisition(pareto_model=self.pareto_cpe, pref_model=self.preference_cpe, prior_dist=prior)\n",
    "        self.labeller = ParetoAnnealed(percentile=0.75, T=N_ITER)\n",
    "\n",
    "    def fit(self, X, y, round):\n",
    "        print(\"Running A-GPS...\")\n",
    "        z = torch.tensor(self.labeller(y), dtype=torch.float)\n",
    "\n",
    "        U = fnn.normalize(y - ref_point, p=2, dim=1)\n",
    "        # Augment dataset with misalignments\n",
    "        Xa, Ua, za = make_constrastive_alignment_data(X, U)\n",
    "        if USE_EMPIRICAL_PREFERENCES:\n",
    "            self.preferences.set_preferences(U[z==1, :] if round > 0 else U)\n",
    "        else:\n",
    "            print(\"Fitting preferences.\")\n",
    "            fit_ml(\n",
    "                self.preferences,\n",
    "                U[z==1, :] if round > 0 else U,\n",
    "                optimizer_options=dict(lr=1e-3, weight_decay=1e-8),\n",
    "                stop_options=dict(n_window=500, maxiter=10000),\n",
    "                callback=callback\n",
    "            )\n",
    "        cpe_opt_options = dict(lr=1e-3, weight_decay=1e-6)\n",
    "        cpe_stop_options = dict(n_window=1000, maxiter=10000)\n",
    "        print(\"Fitting Pareto CPE.\")\n",
    "        fit_cpe_labels(\n",
    "            self.pareto_cpe,\n",
    "            X,\n",
    "            z,\n",
    "            U,\n",
    "            optimizer_options=cpe_opt_options,\n",
    "            stop_options=cpe_stop_options,\n",
    "            callback=callback,\n",
    "            batch_size=32\n",
    "        )\n",
    "        print(\"Fitting Alignment CPE.\")\n",
    "        fit_cpe_labels(\n",
    "            self.preference_cpe,\n",
    "            Xa,\n",
    "            za,\n",
    "            Ua,\n",
    "            optimizer_options=cpe_opt_options,\n",
    "            stop_options=cpe_stop_options,\n",
    "            callback=callback,\n",
    "            batch_size=32\n",
    "        )\n",
    "        print(\"Fitting AGPS.\")\n",
    "        generate_candidates_iw(\n",
    "            self.acq,\n",
    "            self.proposal,\n",
    "            optimizer_options=dict(lr=1e-3),\n",
    "            stop_options=dict(n_window=4000, maxiter=10000),\n",
    "            gradient_samples=SAMPLES,\n",
    "            callback=vsd_callback\n",
    "        )\n",
    "        return self.proposal.sample(torch.Size([BATCH_SIZE]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38f1dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vsd, y_vsd = X_init.clone(), y_init.clone()\n",
    "hv_vsd, hv_comp = [], Hypervolume(ref_point=ref_point)\n",
    "agps = AGPS()\n",
    "for t in range(N_ITER):\n",
    "    Xc, _ = agps.fit(X_vsd, y_vsd, round=t)\n",
    "    yc = bb(Xc)\n",
    "    X_vsd = torch.cat([X_vsd, Xc], dim=0)\n",
    "    y_vsd = torch.cat([y_vsd, yc], dim=0)\n",
    "    hv_vsd.append(hv_comp.compute(y_vsd[is_non_dominated_strict(y_vsd)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edad916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baselines\n",
    "results = {}\n",
    "if M <= 4:\n",
    "    methods = [\"qEHVI\", \"qNEHVI\", \"qNParEGO\"]\n",
    "elif M <= 5:\n",
    "    methods = [\"qNEHVI\", \"qNParEGO\"]\n",
    "else:\n",
    "    methods = [\"qNParEGO\"]\n",
    "\n",
    "for method in methods:\n",
    "    X, Y, hvs = X_init.clone(), y_init.clone(), []\n",
    "    hv_comp = Hypervolume(ref_point=ref_point)\n",
    "    for i in range(N_ITER):\n",
    "        print(f\"Training {method}: {i} ... \", end=\"\")\n",
    "        if method == \"qEHVI\":\n",
    "            moo_model = fit_gp_moo_model(X, Y)\n",
    "            Xc = generate_candidates_qehvi(moo_model, X, Y)\n",
    "        elif method == \"qNEHVI\":\n",
    "            moo_model = fit_gp_moo_model(X, Y)\n",
    "            Xc = generate_candidates_qnehvi(moo_model, X, Y)\n",
    "        else:\n",
    "            sca_model = fit_gp_sca_model(X, Y)\n",
    "            Xc = generate_candidates_nparego(sca_model, X, Y)\n",
    "        yc = bb(Xc)\n",
    "        X = torch.cat([X, Xc], dim=0)\n",
    "        Y = torch.cat([Y, yc], dim=0)\n",
    "        hvs.append(hv_comp.compute(Y[is_non_dominated_strict(Y)]))\n",
    "        print(\"Done!\")\n",
    "    results[method] = hvs\n",
    "\n",
    "# Plot\n",
    "plt.figure(dpi=150, figsize=(8, 5))\n",
    "plt.plot(hv_vsd, label=\"A-GPS\", marker='o')\n",
    "for method in results:\n",
    "    plt.plot(results[method], label=method, marker='x')\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Hypervolume\")\n",
    "plt.title(f\"{FUNCTION}: Hypervolume Comparison\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0995250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate conditioning\n",
    "np.set_printoptions(suppress=True, precision=2) # Set the precision of the output to 3\n",
    "condsamples = 100\n",
    "yplt = y_vsd[is_non_dominated_strict(y_vsd)]\n",
    "yplt -= ref_point\n",
    "\n",
    "if M > 2:\n",
    "    pca = PCA(n_components=2)\n",
    "    yplt = torch.tensor(pca.fit_transform(yplt.numpy()))\n",
    "    pref = pca.transform(ref_point.numpy()[np.newaxis, :]).flatten()\n",
    "else:\n",
    "    pref = ref_point\n",
    "\n",
    "uf1 = torch.tensor([torch.quantile(yplt[:, 0], q=0.9), torch.quantile(yplt[:, 1], q=0.1)])\n",
    "uf2 = torch.tensor([yplt[:, 0].mean(), yplt[:, 1].mean()])\n",
    "uf3 = torch.tensor([torch.quantile(yplt[:, 0], q=0.1), torch.quantile(yplt[:, 1], q=0.9)])\n",
    "\n",
    "start = (pref[0].item(), pref[1].item())\n",
    "cols = plt.cm.inferno([0.1, 0.5, 0.9])\n",
    "plt.figure(dpi=150, figsize=(8, 5))\n",
    "plt.plot(*start, \"ks\", label=\"Reference point\")\n",
    "for uf, marker, col in zip([uf1, uf2, uf3], [\"x\", '+', '.'], cols):\n",
    "    if M > 2:\n",
    "        uf = torch.tensor(pca.inverse_transform(uf.numpy()))\n",
    "    uf = fnn.normalize(uf, p=2, dim=-1)\n",
    "    ufs = torch.tile(uf, (condsamples, 1))\n",
    "    xcand, _ = agps.proposal.cproposal(ufs)\n",
    "    ycand = bb(xcand)\n",
    "    if M > 2:\n",
    "        ycand = torch.tensor(pca.transform(ycand.numpy()))\n",
    "    plt.plot(*ycand.T, marker, label=f\"u = {uf.numpy()}\", c=col, markersize=10,\n",
    "             alpha=0.7, mew=2)\n",
    "    if M > 2:\n",
    "        uf = pca.transform(uf.numpy()[np.newaxis, :]).squeeze()\n",
    "    dx, dy = uf[0].item() / 2, uf[1].item() / 2\n",
    "    end = (start[0] + dx, start[1] + dy)\n",
    "    plt.annotate(\n",
    "        \"\",  # no text\n",
    "        xy=end,  # arrow head at 'end'\n",
    "        xytext=start,  # arrow tail at 'start'\n",
    "        arrowprops={\n",
    "            \"arrowstyle\": \"->\",\n",
    "            \"color\": col,\n",
    "            \"lw\": 2,\n",
    "            \"shrinkA\": 0,\n",
    "            \"shrinkB\": 0,\n",
    "        },\n",
    "    )\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.title(FUNCTION)\n",
    "plt.xlabel(\"$f_1$\")\n",
    "plt.ylabel(\"$f_2$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bba4547",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {m: [] for m in methods + [\"A-GPS\"]}\n",
    "\n",
    "# Run A-GPS multiple times\n",
    "for run in range(N_REPS):\n",
    "    X_vsd, y_vsd = X_init.clone(), y_init.clone()\n",
    "    hv_vsd = []\n",
    "    hv_comp = Hypervolume(ref_point=ref_point)\n",
    "    agps = AGPS()\n",
    "    hv_init = hv_comp.compute(y_vsd[is_non_dominated_strict(y_vsd)])\n",
    "    hv_vsd.append(1.)\n",
    "    for t in range(N_ITER):\n",
    "        Xc, _ = agps.fit(X_vsd, y_vsd, t)\n",
    "        yc = bb(Xc)\n",
    "        X_vsd = torch.cat([X_vsd, Xc], dim=0)\n",
    "        y_vsd = torch.cat([y_vsd, yc], dim=0)\n",
    "        hv = hv_comp.compute(y_vsd[is_non_dominated_strict(y_vsd)]) / hv_init\n",
    "        hv_vsd.append(hv)\n",
    "    results[\"A-GPS\"].append(hv_vsd)\n",
    "\n",
    "# Run baselines\n",
    "for method in methods:\n",
    "    for run in range(N_REPS):\n",
    "        X, Y, hvs = X_init.clone(), y_init.clone(), []\n",
    "        hv_comp = Hypervolume(ref_point=ref_point)\n",
    "        hv_init = hv_comp.compute(Y[is_non_dominated_strict(Y)])\n",
    "        hvs.append(1.)\n",
    "        for i in range(N_ITER):\n",
    "            print(f\"Training {method}: {i} ... \", end=\"\")\n",
    "            if method == \"qEHVI\":\n",
    "                moo_model = fit_gp_moo_model(X, Y)\n",
    "                Xc = generate_candidates_qehvi(moo_model, X, Y)\n",
    "            elif method == \"qNEHVI\":\n",
    "                moo_model = fit_gp_moo_model(X, Y)\n",
    "                Xc = generate_candidates_qnehvi(moo_model, X, Y)\n",
    "            else:\n",
    "                sca_model = fit_gp_sca_model(X, Y)\n",
    "                Xc = generate_candidates_nparego(sca_model, X, Y)\n",
    "            yc = bb(Xc)\n",
    "            X = torch.cat([X, Xc], dim=0)\n",
    "            Y = torch.cat([Y, yc], dim=0)\n",
    "            print(\"Done!\")\n",
    "            hv = hv_comp.compute(Y[is_non_dominated_strict(Y)]) / hv_init\n",
    "            hvs.append(hv)\n",
    "        results[method].append(hvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a42182",
   "metadata": {},
   "outputs": [],
   "source": [
    "LINECYCLE = cycle(\n",
    "    [\n",
    "        \"-\",\n",
    "        \"--\",\n",
    "        \":\",\n",
    "        \"-.\",\n",
    "        (0, (3, 1, 1, 1)),\n",
    "        (0, (5, 1)),\n",
    "        (0, (3, 1, 1, 1, 1, 1)),\n",
    "        (0, (1, 1)),\n",
    "    ]\n",
    ")\n",
    "cycler = plt.cycler(\n",
    "        color=plt.cm.viridis(np.linspace(0.05, 0.95, 4))\n",
    "    ) + plt.cycler(linestyle=[next(LINECYCLE) for _ in range(4)])\n",
    "plt.rc(\"axes\", prop_cycle=cycler)\n",
    "\n",
    "plt.figure(dpi=150, figsize=(8, 5))\n",
    "\n",
    "for method, hvs in results.items():\n",
    "    hvs_array = np.array(hvs)\n",
    "    mean = hvs_array.mean(axis=0)\n",
    "    std = hvs_array.std(axis=0)\n",
    "    lower = mean - std\n",
    "    upper = mean + std\n",
    "    print(f\"{method} :\")\n",
    "    for i, (m, s) in enumerate(zip(mean, std)):\n",
    "        print(f\"  {i}: {m:.3f} ({s:.3f})\")\n",
    "\n",
    "    plt.plot(\n",
    "        mean,\n",
    "        label=method,\n",
    "        marker='o' if method == 'A-GPS' else 'x',\n",
    "        markersize=10,\n",
    "        linewidth=3,\n",
    "    )\n",
    "    plt.fill_between(range(N_ITER+1), lower, upper, alpha=0.2)\n",
    "\n",
    "plt.xlabel(\"Round\")\n",
    "plt.ylabel(\"Relative Hyper-volume\")\n",
    "plt.title(FUNCTION)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f232d370",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
